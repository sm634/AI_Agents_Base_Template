{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825db115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from connectors.maximo_connector import MaximoConnector\n",
    "\n",
    "# instantiate maximo connector.\n",
    "maximo_connector = MaximoConnector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52edf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Union, Any\n",
    "from langchain.agents import tool\n",
    "import ast\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class MaximoAgentTools:\n",
    "\n",
    "    class MaiximoPayloadInput(BaseModel):\n",
    "        maximo_payload: Union[Dict, str] = Field(description=\"The payload to be sent to Maximo.\")\n",
    "\n",
    "    @tool(args_schema=MaiximoPayloadInput)\n",
    "    def perform_maximo_operation(maximo_payload: Union[Dict, str]):\n",
    "        \"\"\"\n",
    "        Perform maximo operation for API requests.\n",
    "        :param state: The state of the agent containing the user input and states to be updated.\n",
    "        :return: A dictionary containing the Maximo payload.\n",
    "        \"\"\"\n",
    "        # Check to see the maximo payload returned, and the response type to perform the correct action.\n",
    "        if isinstance(maximo_payload, str):\n",
    "            maximo_payload = ast.literal_eval(maximo_payload)\n",
    "\n",
    "        request_type = maximo_payload.get(\"request_type\")\n",
    "        params = maximo_payload.get(\"params\")\n",
    "\n",
    "        if request_type.lower() == 'get':\n",
    "            result = maximo_connector.get_workorder_details(params)\n",
    "        elif request_type.lower() == 'post':\n",
    "            result = maximo_connector.post_workorder_details(params)\n",
    "        else:\n",
    "            result = {\n",
    "                \"message\": \"This query is not related to Maximo.\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"maximo_agent_response\": result\n",
    "        }\n",
    "    \n",
    "\n",
    "    class MaximoPayloadGeneratorInput(BaseModel):\n",
    "        user_input: str = Field(description=\"Thing to search for\")\n",
    "        system_prompt: SystemMessage = Field(description=\"System prompt to use for generating the payload\")\n",
    "        llm: Any = Field(description=\"LLM to use for generating the payload\")\n",
    "\n",
    "\n",
    "    @tool(args_schema=MaximoPayloadGeneratorInput)\n",
    "    def generate_maximo_payload(user_input, system_prompt, llm) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generates the Maximo payload based on the user input.\n",
    "        :param state: The state of the agent containing the user input and to be updated.\n",
    "        :return: A dictionary containing the Maximo payload.\n",
    "        \"\"\"\n",
    "        # Check if the user input is classified as a Maximo operation\n",
    "        user_input = HumanMessage(\n",
    "            content=user_input\n",
    "        )\n",
    "        messages = [\n",
    "            system_prompt,\n",
    "            user_input,\n",
    "        ]\n",
    "\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        # validate do a dict.\n",
    "        maximo_payload = ast.literal_eval(response.content)\n",
    "\n",
    "        return maximo_payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eda39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import ChatWatsonx\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"mistralai/mistral-large\",\n",
    "    apikey=os.environ[\"IBM_CLOUD_APIKEY\"],\n",
    "    url=os.environ[\"WATSONX_URL\"],\n",
    "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
    ")\n",
    "\n",
    "query_maximo_tool = [MaximoAgentTools.generate_maximo_payload, MaximoAgentTools.perform_maximo_operation]\n",
    "\n",
    "\n",
    "maximo_agent = model.bind_tools(query_maximo_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c02489a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'messages', 'AIMessage'],\n",
       " 'kwargs': {'content': ' Hello! How can I assist you today?',\n",
       "  'response_metadata': {'token_usage': {'completion_tokens': 10,\n",
       "    'prompt_tokens': 622,\n",
       "    'total_tokens': 632},\n",
       "   'model_name': 'mistralai/mistral-large',\n",
       "   'system_fingerprint': '',\n",
       "   'finish_reason': 'stop'},\n",
       "  'type': 'ai',\n",
       "  'id': 'chatcmpl-5dee96b99f44af118443b32ab0c33a40',\n",
       "  'usage_metadata': {'input_tokens': 622,\n",
       "   'output_tokens': 10,\n",
       "   'total_tokens': 632},\n",
       "  'tool_calls': [],\n",
       "  'invalid_tool_calls': []}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = maximo_agent.invoke(\"hello\")\n",
    "result1.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3182d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'messages', 'AIMessage'],\n",
       " 'kwargs': {'content': '',\n",
       "  'additional_kwargs': {'tool_calls': [{'id': 'mXRZWFKtU',\n",
       "     'type': 'function',\n",
       "     'function': {'name': 'generate_maximo_payload',\n",
       "      'arguments': '{\"user_input\": \"Get the work order details for workorder 12345\", \"system_prompt\": {\"content\": \"You handle user requests by generating a payload for a Maximo provider, based on the user request.\"}, \"llm\": \"chat-350k\"}'}}]},\n",
       "  'response_metadata': {'token_usage': {'completion_tokens': 83,\n",
       "    'prompt_tokens': 635,\n",
       "    'total_tokens': 718},\n",
       "   'model_name': 'mistralai/mistral-large',\n",
       "   'system_fingerprint': '',\n",
       "   'finish_reason': 'tool_calls'},\n",
       "  'type': 'ai',\n",
       "  'id': 'chatcmpl-a8b66d3ca5dd36a983e26c11749b8f0b',\n",
       "  'tool_calls': [{'name': 'generate_maximo_payload',\n",
       "    'args': {'user_input': 'Get the work order details for workorder 12345',\n",
       "     'system_prompt': {'content': 'You handle user requests by generating a payload for a Maximo provider, based on the user request.'},\n",
       "     'llm': 'chat-350k'},\n",
       "    'id': 'mXRZWFKtU',\n",
       "    'type': 'tool_call'}],\n",
       "  'usage_metadata': {'input_tokens': 635,\n",
       "   'output_tokens': 83,\n",
       "   'total_tokens': 718},\n",
       "  'invalid_tool_calls': []}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = maximo_agent.invoke(\"Get the workorder details for workorder 12345?\")\n",
    "result2.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3821b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce3eecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_maximo_payload',\n",
       "  'args': {'user_input': 'Get the work order details for workorder 12345',\n",
       "   'system_prompt': {'content': 'You handle user requests by generating a payload for a Maximo provider, based on the user request.'},\n",
       "   'llm': 'chat-350k'},\n",
       "  'id': 'mXRZWFKtU',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in result2.tool_calls:\n",
    "    selected_tool = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
